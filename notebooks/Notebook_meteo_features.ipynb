{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import ee # L'API de Google Earth Engine\n",
    "ee.Initialize(project=\"ee-azizagrebi4\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_countries = [\"Benin\", \"Burkina\", \"Guinee\", \"Mali\", \"Niger\", \"Togo\"]\n",
    "date_methods = [\"datetime\", \"str\", \"datetime\", \"datetime\", \"datetime\", \"int\"]\n",
    "\n",
    "dem_to_inference = {\n",
    "    \"Benin\": \"Benin\",\n",
    "    \"Burkina\": \"BF\",\n",
    "    \"Guinee\": \"gui\",\n",
    "    \"Mali\": \"Mali\",\n",
    "    \"Niger\": \"Niger\",\n",
    "    \"Togo\": \"Togo\",\n",
    "}\n",
    "\n",
    "training_num = 3\n",
    "dem_country = dem_countries[training_num]\n",
    "inference_country = dem_to_inference[dem_country]\n",
    "\n",
    "training_df = pd.read_excel(f\"Training_data/{inference_country}.xlsx\")\n",
    "if date_methods[training_num] == \"datetime\": # On filtre ici les dates supérieures à 2002 (car pas de données sur ee avant ça)\n",
    "    training_df[\"DATE\"] = pd.to_datetime(training_df[\"DATE\"], errors=\"coerce\")\n",
    "    training_df = training_df[(training_df[\"DATE\"].dt.year > 2002) & (training_df[\"DATE\"].dt.year < 2025)]\n",
    "elif date_methods[training_num] == \"str\":\n",
    "    training_df = training_df[training_df[\"DATE\"].apply(lambda row: int(row.split(\"/\")[2])) > 2002]\n",
    "else:\n",
    "    training_df = training_df[training_df[\"DATE\"] > 2002]\n",
    "training_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration(area_km2): # Constante de temps associée à différentes tailles de bassin versant\n",
    "    if area_km2 < 100:\n",
    "        return 30\n",
    "    elif area_km2 < 500:\n",
    "        return 60\n",
    "    elif area_km2 < 1000:\n",
    "        return 90\n",
    "    elif area_km2 < 3000 :\n",
    "        return 120\n",
    "    elif area_km2 < 5000:\n",
    "        return 150\n",
    "    elif area_km2 < 10000:\n",
    "        return 180\n",
    "    return 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée ici les features météorologiques\n",
    "\n",
    "hydrobasins = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_12') # Hydrobassin qui permet de délimiter les bassins versants (niveau 12, i.e. résolution max)\n",
    "chirps = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\") # Dataset pour la pluviométrie\n",
    "modis_ndvi = ee.ImageCollection('MODIS/006/MOD13A1').select(\"NDVI\") # Dataset pour le NDVI\n",
    "\n",
    "SAVE_PATH = f\"Meteo_features_{dem_country}_time_series.csv\"\n",
    "\n",
    "def get_time_series(lon, lat, date_str):\n",
    "    if type(date_str)==str:\n",
    "        try:\n",
    "            date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "        except:\n",
    "            date = datetime.strptime(date_str, \"%d/%m/%Y\")\n",
    "    else:\n",
    "        date = date_str\n",
    "\n",
    "    start_date = date - timedelta(days=150)\n",
    "    start_date_str, end_date_str = start_date.strftime('%Y-%m-%d'), date.strftime('%Y-%m-%d')\n",
    "\n",
    "    point = ee.Geometry.Point([lon, lat])\n",
    "    bassin = hydrobasins.filterBounds(point).first()\n",
    "    if bassin is None:\n",
    "        return None, None \n",
    "\n",
    "    bassin_geom = bassin.geometry()\n",
    "\n",
    "    chirps_filtered = chirps.filterDate(start_date_str, end_date_str)\n",
    "\n",
    "    def extract_rainfall(img):\n",
    "        date = ee.Date(img.date()).format(\"YYYY-MM-dd\")\n",
    "        mean_rainfall = img.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=bassin_geom,\n",
    "            scale=5000,\n",
    "            maxPixels=1e9\n",
    "        ).get(\"precipitation\")\n",
    "        return ee.Feature(None, {\"date\": date, \"precipitation\": mean_rainfall})\n",
    "\n",
    "    rainfall_series = chirps_filtered.map(extract_rainfall).aggregate_array(\"date\").getInfo()\n",
    "    rainfall_values = chirps_filtered.map(extract_rainfall).aggregate_array(\"precipitation\").getInfo()\n",
    "\n",
    "    ndvi_filtered = modis_ndvi.filterDate(start_date_str, end_date_str)\n",
    "\n",
    "    def extract_ndvi(img):\n",
    "        date = ee.Date(img.date()).format(\"YYYY-MM-dd\")\n",
    "        mean_ndvi = img.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=bassin_geom,\n",
    "            scale=500,\n",
    "            maxPixels=1e9\n",
    "        ).get(\"NDVI\")\n",
    "        return ee.Feature(None, {\"date\": date, \"NDVI\": mean_ndvi})\n",
    "\n",
    "    ndvi_series = ndvi_filtered.map(extract_ndvi).aggregate_array(\"date\").getInfo()\n",
    "    ndvi_values = ndvi_filtered.map(extract_ndvi).aggregate_array(\"NDVI\").getInfo()\n",
    "\n",
    "    ndvi_values = [v * 0.0001 if v is not None else None for v in ndvi_values]\n",
    "\n",
    "    return list(zip(rainfall_series, rainfall_values)), list(zip(ndvi_series, ndvi_values))\n",
    "\n",
    "if os.path.exists(SAVE_PATH):\n",
    "    training_df = pd.read_csv(SAVE_PATH, index_col=0)\n",
    "    start_index = training_df[training_df[\"ndvi_series\"]==training_df[\"ndvi_series\"]].index[-1]\n",
    "    print(f\"Reprise depuis l'index {start_index}\")\n",
    "else:\n",
    "    training_df[\"precipitation_series\"] = None\n",
    "    training_df[\"ndvi_series\"] = None\n",
    "    start_index = -1\n",
    "\n",
    "for k, i in enumerate(training_df.index):\n",
    "    if i > start_index:\n",
    "        lon, lat, date_str = training_df.loc[i, \"LON\"], training_df.loc[i, \"LAT\"], training_df.loc[i, \"DATE\"]\n",
    "        \n",
    "        print(f\"Traitement de l'index {k}/{len(training_df)} : LON={lon}, LAT={lat}, DATE={date_str}\")\n",
    "\n",
    "        precipitation_series, ndvi_series = get_time_series(lon, lat, date_str)\n",
    "        \n",
    "        training_df.at[i, \"precipitation_series\"] = str(precipitation_series)\n",
    "        training_df.at[i, \"ndvi_series\"] = str(ndvi_series)\n",
    "\n",
    "        if k % 10 == 0 or k == len(training_df) - 1:\n",
    "            training_df.to_csv(SAVE_PATH, index=True)\n",
    "            print(f\"Sauvegarde à l'index {i}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
